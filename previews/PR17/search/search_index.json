{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#tidierfilesjl","title":"TidierFiles.jl","text":""},{"location":"#what-is-tidierfilesjl","title":"What is TidierFiles.jl?","text":"<p>TidierFiles.jl is a 100% Julia implementation of the readr, haven, readxl, and writexl R packages.</p> <p>Powered by the CSV.jl, XLSX.jl, ReadStatTables.jl, Arrow.jl and Parquet2.jl packages, TidierFiles.jl aims to bring a consistent interface to the reading and writing of tabular data, including a consistent syntax to read files locally versus from the web and consistent keyword arguments across data formats.</p> <p>Currently supported file types:</p> <ul> <li><code>read_csv</code> and <code>write_csv</code></li> <li><code>read_tsv</code> and <code>write_tsv</code></li> <li><code>read_xlsx</code> and <code>write_xlsx</code></li> <li><code>read_delim</code> and <code>write_delim</code></li> <li><code>read_table</code> and <code>write_table</code></li> <li><code>read_fwf</code> and <code>fwf_empty</code></li> <li><code>read_sav</code> and <code>write_sav</code> (.sav and .por)</li> <li><code>read_sas</code> and <code>write_sas</code> (.sas7bdat and .xpt)</li> <li><code>read_dta</code> and <code>write_dta</code> (.dta)</li> <li><code>read_arrow</code> and <code>write_arrow</code></li> <li><code>read_parquet</code> and <code>write_parquet</code></li> <li><code>read_rdata</code> (.rdata and .rds)</li> </ul> <p>Agnostic read and write functions that detect the type and dispatch the appropriate function. </p> <ul> <li><code>read_file</code> and <code>write_file</code></li> </ul> <p></p> <p></p>"},{"location":"#examples","title":"Examples","text":"<p>Here is an example of how to write and read a CSV file.</p> <pre><code>using TidierFiles\n\ndf = DataFrame(\n       integers = [1, 2, 3, 4],\n       strings = [\"This\", \"Package makes\", \"File reading/writing\", \"even smoother\"],\n       floats = [10.2, 20.3, 30.4, 40.5],\n       dates = [Date(2018,2,20), Date(2018,2,21), Date(2018,2,22), Date(2018,2,23)],\n       times = [Dates.Time(19,10), Dates.Time(19,20), Dates.Time(19,30), Dates.Time(19,40)]\n     )\n\nwrite_csv(df, \"testing.csv\" , col_names = true)\n\nread_csv(\"testing.csv\", missingstring=[\"40.5\", \"10.2\"])\n</code></pre> <pre><code>4\u00d75 DataFrame\n Row \u2502 integers  strings               floats     dates       times    \n     \u2502 Int64     String31              Float64?   Date        Time     \n\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n   1 \u2502        1  This                  missing    2018-02-20  19:10:00\n   2 \u2502        2  Package makes              20.3  2018-02-21  19:20:00\n   3 \u2502        3  File reading/writing       30.4  2018-02-22  19:30:00\n   4 \u2502        4  even smoother         missing    2018-02-23  19:40:00:00\n</code></pre> <p>The file reading functions include the following keyword arguments:</p> <ul> <li><code>path</code></li> <li><code>missingstring</code></li> <li><code>col_names</code></li> <li><code>col_select</code></li> <li><code>num_threads</code></li> <li><code>skip</code></li> <li><code>n_max</code></li> <li><code>delim</code> (where applicable)</li> </ul> <p>The path can be a file available either locally or on the web.</p> <pre><code>read_csv(\"https://raw.githubusercontent.com/TidierOrg/TidierFiles.jl/main/testing_files/csvtest.csv\", skip = 2, n_max = 3, col_select = [\"ID\", \"Score\"], missingstring = [\"4\"])\n</code></pre> <pre><code>3\u00d72 DataFrame\n Row \u2502 ID       Score \n     \u2502 Int64?   Int64 \n\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n   1 \u2502       3     77\n   2 \u2502 missing     85\n   3 \u2502       5     95\n</code></pre> <p>Read multiple files by passing paths as a vector. </p> <pre><code>path = \"https://raw.githubusercontent.com/TidierOrg/TidierFiles.jl/main/testing_files/csvtest.csv\"\nread_csv([path, path], skip=3)\n</code></pre> <pre><code>4\u00d73 DataFrame\n Row \u2502 ID     Name     Score \n     \u2502 Int64  String7  Int64 \n\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n   1 \u2502     4  David       85\n   2 \u2502     5  Eva         95\n   3 \u2502     4  David       85\n   4 \u2502     5  Eva         95\n</code></pre>"},{"location":"reference/","title":"Reference","text":""},{"location":"reference/#index","title":"Index","text":"<ul> <li><code>TidierFiles.fwf_empty</code></li> <li><code>TidierFiles.read_arrow</code></li> <li><code>TidierFiles.read_csv</code></li> <li><code>TidierFiles.read_delim</code></li> <li><code>TidierFiles.read_dta</code></li> <li><code>TidierFiles.read_file</code></li> <li><code>TidierFiles.read_fwf</code></li> <li><code>TidierFiles.read_parquet</code></li> <li><code>TidierFiles.read_rdata</code></li> <li><code>TidierFiles.read_sas</code></li> <li><code>TidierFiles.read_sav</code></li> <li><code>TidierFiles.read_table</code></li> <li><code>TidierFiles.read_tsv</code></li> <li><code>TidierFiles.read_xlsx</code></li> <li><code>TidierFiles.write_arrow</code></li> <li><code>TidierFiles.write_csv</code></li> <li><code>TidierFiles.write_dta</code></li> <li><code>TidierFiles.write_file</code></li> <li><code>TidierFiles.write_parquet</code></li> <li><code>TidierFiles.write_sas</code></li> <li><code>TidierFiles.write_sav</code></li> <li><code>TidierFiles.write_table</code></li> <li><code>TidierFiles.write_tsv</code></li> <li><code>TidierFiles.write_xlsx</code></li> </ul>"},{"location":"reference/#reference-exported-functions","title":"Reference - Exported functions","text":"<p># <code>TidierFiles.fwf_empty</code> \u2014 Method.</p> <pre><code>fwf_empty(filepath::String; num_lines::Int=4, col_names=nothing)\n</code></pre> <p>Analyze a fixed-width format (FWF) file to automatically determine column widths and provide column names.</p> <p>Arguments</p> <ul> <li><code>filepath</code>::String: Path to the FWF file to analyze.</li> </ul> <p>num_lines::Int=4: Number of lines to sample from the beginning of the file for analysis. Default is 4.</p> <ul> <li><code>col_names</code>: Optional; a vector of strings specifying column names. If not provided, column names are generated as Column1, Column2, etc.</li> </ul> <p>Returns</p> <ul> <li>A tuple containing two elements:</li> <li>A vector of integers representing the detected column widths.</li> <li>A vector of strings representing the column names.</li> </ul> <p>Examples</p> <pre><code>julia&gt; fwf_data = \n       \"John Smith   35    12345  Software Engineer   120,000 \\nJane Doe     29     2345  Marketing Manager   95,000  \\nAlice Jones  42   123456  CEO                 250,000 \\nBob Brown    31    12345  Product Manager     110,000 \\nCharlie Day  28      345  Sales Associate     70,000  \\nDiane Poe    35    23456  Data Scientist      130,000 \\nEve Stone    40   123456  Chief Financial Off 200,000 \\nFrank Moore  33     1234  Graphic Designer    80,000  \\nGrace Lee    27   123456  Software Developer  115,000 \\nHank Zuse    45    12345  System Analyst      120,000 \";\n\njulia&gt; open(\"fwftest.txt\", \"w\") do file\n         write(file, fwf_data)\n       end;\n\njulia&gt; path = \"fwftest.txt\";\n\njulia&gt; fwf_empty(path)\n([13, 5, 8, 20, 8], [\"Column_1\", \"Column_2\", \"Column_3\", \"Column_4\", \"Column_5\"])\n\njulia&gt; fwf_empty(path, num_lines=4, col_names = [\"Name\", \"Age\", \"ID\", \"Position\", \"Salary\"])\n([13, 5, 8, 20, 8], [\"Name\", \"Age\", \"ID\", \"Position\", \"Salary\"])\n</code></pre> <p>source</p> <p># <code>TidierFiles.read_arrow</code> \u2014 Method.</p> <pre><code>read_arrow(df, path)\n</code></pre> <p>Read an Arrow file (.arrow) to a DataFrame.</p> <p>Arguments</p> <ul> <li><code>df</code>: The DataFrame to be written to a file.</li> <li><code>path</code>: String as path where the .dta file will be created. If a file at this path already exists, it will be overwritten.</li> <li><code>skip</code>: Number of initial lines to skip before reading data. Default is 0.</li> <li><code>n_max</code>: Maximum number of rows to read. Default is Inf (read all rows).</li> <li><code>col_select</code>: Optional vector of symbols or strings to select which columns to load.</li> </ul> <p>Examples</p> <pre><code>julia&gt; df = DataFrame(AA=[\"Arr\", \"ow\"], AB=[10.1, 10.2]);\n\njulia&gt; write_arrow(df , \"test.arrow\");\n\njulia&gt; read_arrow(\"test.arrow\")\n2\u00d72 DataFrame\n Row \u2502 AA      AB      \n     \u2502 String  Float64 \n\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n   1 \u2502 Arr        10.1\n   2 \u2502 ow         10.2\n</code></pre> <p>source</p> <p># <code>TidierFiles.read_csv</code> \u2014 Method.</p> <pre><code>read_csv(file; delim=',',col_names=true, skip=0, n_max=Inf, \n    comment=nothing, missingstring=\"\", col_select, escape_double=true, col_types=nothing, num_threads = 1)\n</code></pre> <p>Reads a CSV file or URL into a DataFrame, with options to specify delimiter, column names, and other CSV parsing options.</p> <p>Arguments</p> <ul> <li><code>file</code>: Path or vector of paths to the CSV file or a URL to a CSV file.</li> <li><code>delim</code>: The character delimiting fields in the file. Default is ','.</li> <li><code>col_names</code>: Indicates if the first row of the CSV is used as column names. Can be true, false, or an array of strings. Default is true.</li> <li><code>skip</code>: Number of initial lines to skip before reading data. Default is 0.</li> <li><code>n_max</code>: Maximum number of rows to read. Default is Inf (read all rows).</li> <li><code>col_select</code>: Optional vector of symbols or strings to select which columns to load.</li> <li><code>comment</code>: Character that starts a comment line. Lines beginning with this character are ignored. Default is nothing (no comment lines).</li> <li><code>missingstring</code>: String that represents missing values in the CSV. Default is \"\", can be set to a vector of multiple items.</li> <li><code>escape_double</code>: Indicates whether to interpret two consecutive quote characters as a single quote in the data. Default is true.</li> <li><code>num_threads</code>: specifies the number of concurrent tasks or threads to use for processing, allowing for parallel execution. Defaults to 1</li> </ul> <p>Examples</p> <pre><code>julia&gt; df = DataFrame(ID = 1:5, Name = [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eva\"], Score = [88, 92, 77, 85, 95]);\n\njulia&gt; write_csv(df, \"csvtest.csv\");\n\njulia&gt; read_csv(\"csvtest.csv\", skip = 2, n_max = 3, missingstring = [\"95\", \"Charlie\"])\n3\u00d73 DataFrame\n Row \u2502 ID     Name     Score   \n     \u2502 Int64  String7  Int64?  \n\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n   1 \u2502     3  missing       77\n   2 \u2502     4  David         85\n   3 \u2502     5  Eva      missing \n</code></pre> <p>source</p> <p># <code>TidierFiles.read_delim</code> \u2014 Method.</p> <pre><code>read_delim(file; delim='    ',col_names=true, skip=0, n_max=Inf, \n    comment=nothing, missingstring=\"\", col_select, escape_double=true, col_types=nothing)\n</code></pre> <p>Reads a delimited file or URL into a DataFrame, with options to specify delimiter, column names, and other CSV parsing options.</p> <p>Arguments</p> <ul> <li><code>file</code>: Path or vector of paths to the CSV file or a URL to a CSV file.</li> <li><code>delim</code>: The character delimiting fields in the file. Default is ','.</li> <li><code>col_names</code>: Indicates if the first row of the CSV is used as column names. Can be true, false, or an array of strings. Default is true.</li> <li><code>skip</code>: Number of initial lines to skip before reading data. Default is 0.</li> <li><code>n_max</code>: Maximum number of rows to read. Default is Inf (read all rows).</li> <li><code>col_select</code>: Optional vector of symbols or strings to select which columns to load.</li> <li><code>comment</code>: Character that starts a comment line. Lines beginning with this character are ignored. Default is nothing (no comment lines).</li> <li><code>missingstring</code>: String that represents missing values in the CSV. Default is \"\", can be set to a vector of multiple items.</li> <li><code>escape_double</code>: Indicates whether to interpret two consecutive quote characters as a single quote in the data. Default is true.</li> <li><code>col_types</code>: An optional specification of column types, can be a single type applied to all columns, or a collection of types with one for each column. Default is nothing (types are inferred).</li> <li><code>num_threads</code>: specifies the number of concurrent tasks or threads to use for processing, allowing for parallel execution. Default is the number of available threads.</li> </ul> <p>Examples</p> <pre><code>julia&gt; df = DataFrame(ID = 1:5, Name = [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eva\"], Score = [88, 92, 77, 85, 95]);\n\njulia&gt; write_csv(df, \"csvtest.csv\");\n\njulia&gt; read_delim(\"csvtest.csv\", delim = \",\", col_names = false, num_threads = 4) # col_names are false here for the purpose of demonstration\n6\u00d73 DataFrame\n Row \u2502 Column1  Column2  Column3 \n     \u2502 String3  String7  String7 \n\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n   1 \u2502 ID       Name     Score\n   2 \u2502 1        Alice    88\n   3 \u2502 2        Bob      92\n   4 \u2502 3        Charlie  77\n   5 \u2502 4        David    85\n   6 \u2502 5        Eva      95\n</code></pre> <p>source</p> <p># <code>TidierFiles.read_dta</code> \u2014 Method.</p> <pre><code>function read_dta(data_file;  encoding=nothing, col_select=nothing, skip=0, n_max=Inf)\n</code></pre> <p>Read data from a Stata (.dta) file into a DataFrame, supporting both local and remote sources.</p> <p>Arguments</p> <ul> <li><code>filepath</code>: The path to the .dta file or a URL pointing to such a file. If a URL is provided, the file will be downloaded and then read.</li> </ul> <p><code>encoding</code>: Optional; specifies the encoding of the input file. If not provided, defaults to the package's or function's default. <code>col_select</code>: Optional; allows specifying a subset of columns to read. This can be a vector of column names or indices. If nothing, all columns are read.</p> <ul> <li><code>skip=0</code>: Number of rows at the beginning of the file to skip before reading.</li> <li><code>n_max=Inf</code>: Maximum number of rows to read from the file, after skipping. If Inf, read all available rows.</li> </ul> <p><code>num_threads</code>: specifies the number of concurrent tasks or threads to use for processing, allowing for parallel execution. Defaults to 1</p> <p>Examples</p> <pre><code>julia&gt; df = DataFrame(AA=[\"sav\", \"por\"], AB=[10.1, 10.2]);\n\njulia&gt; write_dta(df, \"test.dta\");\n\njulia&gt; read_dta(\"test.dta\")\n2\u00d72 DataFrame\n Row \u2502 AA       AB      \n     \u2502 String3  Float64 \n\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n   1 \u2502 sav         10.1\n   2 \u2502 por         10.2\n</code></pre> <p>source</p> <p># <code>TidierFiles.read_file</code> \u2014 Method.</p> <pre><code>read_files(path; args)\n</code></pre> <p>Generic file reader that automatically detects type and dispatches the appropriate read function. </p> <p>Arguments</p> <ul> <li><code>path</code> : a string with the file path to read</li> <li><code>args</code> : additional arguments supported for that specific file type are given as they normally would be</li> </ul> <p>Examples</p> <pre><code>julia&gt; df = DataFrame(ID = 1:5, Name = [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eva\"], Score = [88, 92, 77, 85, 95]);\n\njulia&gt; write_parquet(df, \"test.parquet\");\n\njulia&gt; read_file(\"test.parquet\")\n5\u00d73 DataFrame\n Row \u2502 ID     Name     Score \n     \u2502 Int64  String   Int64 \n\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n   1 \u2502     1  Alice       88\n   2 \u2502     2  Bob         92\n   3 \u2502     3  Charlie     77\n   4 \u2502     4  David       85\n   5 \u2502     5  Eva         95\n</code></pre> <p>source</p> <p># <code>TidierFiles.read_fwf</code> \u2014 Method.</p> <pre><code>read_fwf(filepath::String; num_lines::Int=4, col_names=nothing)\n</code></pre> <p>Read fixed-width format (FWF) files into a DataFrame.</p> <p>Arguments</p> <ul> <li><code>filepath</code>::String: Path to the FWF file to read.</li> <li><code>widths_colnames</code>::Tuple{Vector{Int}, Union{Nothing, Vector{String}}}: A tuple containing two elements:       - A vector of integers specifying the widths of each field.       - Optionally, a vector of strings specifying column names. If nothing, column names are generated as Column1, Column2, etc.</li> <li><code>skip_to</code>=0: Number of lines at the beginning of the file to skip before reading data.</li> <li><code>n_max</code>=nothing: Maximum number of lines to read from the file. If nothing, read all lines.</li> </ul> <p>Examples</p> <pre><code>julia&gt; fwf_data = \n       \"John Smith   35    12345  Software Engineer   120,000 \\nJane Doe     29     2345  Marketing Manager   95,000  \\nAlice Jones  42   123456  CEO                 250,000 \\nBob Brown    31    12345  Product Manager     110,000 \\nCharlie Day  28      345  Sales Associate     70,000  \\nDiane Poe    35    23456  Data Scientist      130,000 \\nEve Stone    40   123456  Chief Financial Off 200,000 \\nFrank Moore  33     1234  Graphic Designer    80,000  \\nGrace Lee    27   123456  Software Developer  115,000 \\nHank Zuse    45    12345  System Analyst      120,000 \";\n\njulia&gt; open(\"fwftest.txt\", \"w\") do file\n         write(file, fwf_data)\n       end;\n\njulia&gt; path = \"fwftest.txt\";\n\njulia&gt; read_fwf(path, fwf_empty(path, num_lines=4, col_names = [\"Name\", \"Age\", \"ID\", \"Position\", \"Salary\"]), skip_to=3, n_max=3)\n3\u00d75 DataFrame\n Row \u2502 Name         Age     ID      Position         Salary  \n     \u2502 String       String  String  String           String  \n\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n   1 \u2502 Bob Brown    31      12345   Product Manager  110,000\n   2 \u2502 Charlie Day  28      345     Sales Associate  70,000\n   3 \u2502 Diane Poe    35      23456   Data Scientist   130,000\n</code></pre> <p>source</p> <p># <code>TidierFiles.read_parquet</code> \u2014 Method.</p> <pre><code>read_parquet(path)\n</code></pre> <p>Read a Paquet File (.parquet) to a DataFrame.</p> <p>Arguments</p> <ul> <li><code>path</code>: Path or vector of paths or URLs to parquet file to be read</li> <li><code>col_names</code>: Indicates if the first row of the CSV is used as column names. Can be true, false, or an array of strings. Default is true.</li> <li><code>skip</code>: Number of initial lines to skip before reading data. Default is 0.</li> <li><code>n_max</code>: Maximum number of rows to read. Default is Inf (read all rows).</li> <li><code>col_select</code>: Optional vector of symbols or strings to select which columns to load.</li> </ul> <p>Examples</p> <pre><code>julia&gt; df = DataFrame(AA=[\"Par\", \"quet\"], AB=[10.1, 10.2]);\n\njulia&gt; write_parquet(df, \"test.parquet\");\n\njulia&gt; read_parquet(\"test.parquet\")\n2\u00d72 DataFrame\n Row \u2502 AA      AB      \n     \u2502 String  Float64 \n\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n   1 \u2502 Par        10.1\n   2 \u2502 quet       10.2\n</code></pre> <p>source</p> <p># <code>TidierFiles.read_rdata</code> \u2014 Method.</p> <pre><code>read_rdata(path)\n</code></pre> <p>Read <code>.rdata</code> and <code>.rds</code> files as DataFrame. <code>.rdata</code> files will result in a <code>Dict</code>. Dataframes can then be selected with `result[\"name\"]``</p> <p>Arguments</p> <ul> <li><code>path</code>: A string with the file location. This does not yet support reading from URLs.</li> </ul> <p>source</p> <p># <code>TidierFiles.read_sas</code> \u2014 Method.</p> <pre><code>function read_sas(data_file;  encoding=nothing, col_select=nothing, skip=0, n_max=Inf, num_threads)\n</code></pre> <p>Read data from a SAS (.sas7bdat and .xpt) file into a DataFrame, supporting both local and remote sources.</p> <p>Arguments</p> <ul> <li><code>filepath</code>: The path to the .dta file or a URL pointing to such a file. If a URL is provided, the file will be downloaded and then read.</li> </ul> <p><code>encoding</code>: Optional; specifies the encoding of the input file. If not provided, defaults to the package's or function's default. <code>col_select</code>: Optional; allows specifying a subset of columns to read. This can be a vector of column names or indices. If nothing, all columns are read.</p> <ul> <li><code>skip=0</code>: Number of rows at the beginning of the file to skip before reading.</li> <li><code>n_max=Inf</code>: Maximum number of rows to read from the file, after skipping. If Inf, read all available rows.</li> </ul> <p><code>num_threads</code>: specifies the number of concurrent tasks or threads to use for processing, allowing for parallel execution. Defaults to 1</p> <p>Examples</p> <p>```jldoctest julia&gt; df = DataFrame(AA=[\"sav\", \"por\"], AB=[10.1, 10.2]);</p> <p>julia&gt; write_sas(df, \"test.sas7bdat\");</p> <p>julia&gt; read_sas(\"test.sas7bdat\") 2\u00d72 DataFrame  Row \u2502 AA       AB            \u2502 String3  Float64  \u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500    1 \u2502 sav         10.1    2 \u2502 por         10.2</p> <p>julia&gt; write_sas(df, \"test.xpt\");</p> <p>julia&gt; read_sas(\"test.xpt\") 2\u00d72 DataFrame  Row \u2502 AA       AB            \u2502 String3  Float64  \u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500    1 \u2502 sav         10.1    2 \u2502 por         10.2</p> <p>source</p> <p># <code>TidierFiles.read_sav</code> \u2014 Method.</p> <pre><code>function read_sav(data_file;  encoding=nothing, col_select=nothing, skip=0, n_max=Inf)\n</code></pre> <p>Read data from a SPSS (.sav and .por) file into a DataFrame, supporting both local and remote sources.</p> <p>Arguments</p> <ul> <li><code>filepath</code>: The path to the .sav or .por file or a URL pointing to such a file. If a URL is provided, the file will be downloaded and then read.</li> <li><code>encoding</code>: Optional; specifies the encoding of the input file. If not provided, defaults to the package's or function's default.</li> <li><code>col_select</code>: Optional; allows specifying a subset of columns to read. This can be a vector of column names or indices. If nothing, all columns are read.</li> <li><code>skip=0</code>: Number of rows at the beginning of the file to skip before reading.</li> <li>`n_max=Inf``: Maximum number of rows to read from the file, after skipping. If Inf, read all available rows.</li> <li><code>num_threads</code>: specifies the number of concurrent tasks or threads to use for processing, allowing for parallel execution. Defaults to 1</li> </ul> <p>Examples</p> <pre><code>julia&gt; df = DataFrame(AA=[\"sav\", \"por\"], AB=[10.1, 10.2]);\n\njulia&gt; write_sav(df, \"test.sav\");\n\njulia&gt; read_sav(\"test.sav\")\n2\u00d72 DataFrame\n Row \u2502 AA      AB      \n     \u2502 String  Float64 \n\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n   1 \u2502 sav        10.1\n   2 \u2502 por        10.2\n\njulia&gt; write_sav(df, \"test.por\");\n\njulia&gt; read_sav(\"test.por\")\n2\u00d72 DataFrame\n Row \u2502 AA      AB      \n     \u2502 String  Float64 \n\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n   1 \u2502 sav        10.1\n   2 \u2502 por        10.2\n</code></pre> <p>source</p> <p># <code>TidierFiles.read_table</code> \u2014 Method.</p> <pre><code>read_table(file; col_names=true, skip=0, n_max=Inf, comment=nothing, col_select, missingstring=\"\", kwargs...)\n</code></pre> <p>Read a table from a file where columns are separated by any amount of whitespace, processing it into a DataFrame.</p> <p>Arguments</p> <ul> <li><code>file</code>: The path to the file to read.</li> <li><code>col_names</code>=true: Indicates whether the first non-skipped line should be treated as column names. If false, columns are named automatically.</li> <li><code>skip</code>: Number of lines at the beginning of the file to skip before processing starts.</li> <li><code>n_max</code>: The maximum number of lines to read from the file, after skipping. Inf means read all lines.</li> <li><code>col_select</code>: Optional vector of symbols or strings to select which columns to load.</li> <li><code>comment</code>: A character or string indicating the start of a comment. Lines starting with this character are ignored.</li> <li><code>missingstring</code>: The string that represents missing values in the table.</li> <li><code>kwargs</code>: Additional keyword arguments passed to CSV.File.</li> </ul> <p>Examples</p> <pre><code>julia&gt; df = DataFrame(ID = 1:5, Name = [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eva\"], Score = [88, 92, 77, 85, 95]);\n\njulia&gt; write_table(df, \"tabletest.txt\");\n\njulia&gt; read_table(\"tabletest.txt\", skip = 2, n_max = 3, col_select = [\"Name\"])\n3\u00d71 DataFrame\n Row \u2502 Name    \n     \u2502 String7 \n\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n   1 \u2502 Charlie\n   2 \u2502 David\n   3 \u2502 Eva\n</code></pre> <p>source</p> <p># <code>TidierFiles.read_tsv</code> \u2014 Method.</p> <pre><code>read_tsv(file; delim='  ',col_names=true, skip=0, n_max=Inf, \n    comment=nothing, missingstring=\"\", col_select, escape_double=true, col_types=nothing)\n</code></pre> <p>Reads a TSV file or URL into a DataFrame, with options to specify delimiter, column names, and other CSV parsing options.</p> <p>Arguments</p> <ul> <li><code>file</code>: Path or vector of paths to the TSV file or a URL to a TSV file.</li> <li><code>delim</code>: The character delimiting fields in the file. Default is ','.</li> <li><code>col_names</code>: Indicates if the first row of the CSV is used as column names. Can be true, false, or an array of strings. Default is true.</li> <li><code>skip</code>: Number of initial lines to skip before reading data. Default is 0.</li> <li><code>n_max</code>: Maximum number of rows to read. Default is Inf (read all rows).</li> <li><code>col_select</code>: Optional vector of symbols or strings to select which columns to load.</li> <li><code>comment</code>: Character that starts a comment line. Lines beginning with this character are ignored. Default is nothing (no comment lines).</li> <li><code>missingstring</code>: String that represents missing values in the CSV. Default is \"\", can be set to a vector of multiple items.</li> <li><code>escape_double</code>: Indicates whether to interpret two consecutive quote characters as a single quote in the data. Default is true.</li> <li><code>num_threads</code>: specifies the number of concurrent tasks or threads to use for processing, allowing for parallel execution. Default is the number of available threads.</li> </ul> <p>Examples</p> <pre><code>julia&gt; df = DataFrame(ID = 1:5, Name = [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eva\"], Score = [88, 92, 77, 85, 95]);\n\njulia&gt; write_tsv(df, \"tsvtest.tsv\");\n\njulia&gt; read_tsv(\"tsvtest.tsv\", skip = 2, n_max = 3, missingstring = [\"Charlie\"])\n3\u00d73 DataFrame\n Row \u2502 ID     Name     Score \n     \u2502 Int64  String7  Int64 \n\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n   1 \u2502     3  missing     77\n   2 \u2502     4  David       85\n   3 \u2502     5  Eva         95\n</code></pre> <p>source</p> <p># <code>TidierFiles.read_xlsx</code> \u2014 Method.</p> <pre><code>read_xlsx(path; sheet, range, col_names, col_types, missingstring, trim_ws, skip, n_max, guess_max)\n</code></pre> <p>Read data from an Excel file into a DataFrame.</p> <p>Arguments</p> <ul> <li><code>path</code>: The path to the Excel file to be read.</li> <li><code>sheet</code>: Specifies the sheet to be read. Can be either the name of the sheet as a string or its index as an integer. If nothing, the first sheet is read.</li> <li><code>range</code>: Specifies a specific range of cells to be read from the sheet. If nothing, the entire sheet is read.</li> <li><code>col_names</code>: Indicates whether the first row of the specified range should be treated as column names. If false, columns will be named automatically.</li> <li><code>col_types</code>: Allows specifying column types explicitly. Can be a single type applied to all columns, a list or a dictionary mapping column names or indices to types. If nothing, types will be inferred.</li> <li><code>missingstring</code>: The value or vector that represents missing values in the Excel file.</li> <li><code>trim_ws</code>: Whether to trim leading and trailing whitespace from cells in the Excel file.</li> <li><code>skip</code>: Number of rows to skip at the beginning of the sheet or range before reading data.</li> <li><code>n_max</code>: The maximum number of rows to read from the sheet or range, after skipping. Inf means read all available rows.</li> <li><code>guess_max</code>: The maximum number of rows to scan for type guessing and column names detection. Only relevant if coltypes is nothing or colnames is true. If nothing, a default heuristic is used.</li> </ul> <p>Examples</p> <pre><code>julia&gt; df = DataFrame(integers=[1, 2, 3, 4],\n       strings=[\"This\", \"Package makes\", \"File reading/writing\", \"even smoother\"],\n       floats=[10.2, 20.3, 30.4, 40.5]);\n\njulia&gt; df2 = DataFrame(AA=[\"aa\", \"bb\"], AB=[10.1, 10.2]);\n\njulia&gt; write_xlsx((\"REPORT_A\" =&gt; df, \"REPORT_B\" =&gt; df2); path=\"xlsxtest.xlsx\", overwrite = true);\n\njulia&gt; read_xlsx(\"xlsxtest.xlsx\", sheet = \"REPORT_A\", skip = 1, n_max = 4, missingstring = [2])\n3\u00d73 DataFrame\n Row \u2502 integers  strings               floats  \n     \u2502 Any       String                Float64 \n\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n   1 \u2502 missing   Package makes            20.3\n   2 \u2502 3         File reading/writing     30.4\n   3 \u2502 4         even smoother            40.5\n</code></pre> <p>source</p> <p># <code>TidierFiles.write_arrow</code> \u2014 Method.</p> <pre><code>write_arrow(df, path)\n</code></pre> <p>Write a DataFrame to an Arrow (.arrow) file.</p> <p>Arguments</p> <ul> <li><code>df</code>: The DataFrame to be written to a file.</li> <li><code>path</code>: String as path where the .dta file will be created. If a file at this path already exists, it will be overwritten.</li> </ul> <p>Examples</p> <pre><code>julia&gt; df = DataFrame(AA=[\"Arr\", \"ow\"], AB=[10.1, 10.2]);\n\njulia&gt; write_arrow(df , \"test.arrow\");\n</code></pre> <p>source</p> <p># <code>TidierFiles.write_csv</code> \u2014 Method.</p> <pre><code>write_csv(DataFrame, filepath; na = \"\", append = false, col_names = true, missingstring, eol = \"\n</code></pre> <p>\", num_threads = Threads.nthreads()) Write a DataFrame to a CSV (comma-separated values) file.</p> <p>Arguments</p> <ul> <li><code>x</code>: The DataFrame to write to the CSV file.</li> <li><code>file</code>: The path to the output CSV file.</li> <li><code>missingstring</code>: = \"\": The string to represent missing values in the output file. Default is an empty string.</li> <li><code>append</code>: Whether to append to the file if it already exists. Default is false.</li> <li><code>col_names</code>: = true: Whether to write column names as the first line of the file. Default is true.</li> <li><code>eol</code>: = \"</li> </ul> <p>\": The end-of-line character to use in the output file. Default is the newline character.</p> <ul> <li><code>num_threads</code> = Threads.nthreads(): The number of threads to use for writing the file. Default is the number of available threads.</li> </ul> <p>Examples</p> <pre><code>julia&gt; df = DataFrame(ID = 1:5, Name = [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eva\"], Score = [88, 92, 77, 85, 95]);\n\njulia&gt; write_csv(df, \"csvtest.csv\");\n</code></pre> <p>source</p> <p># <code>TidierFiles.write_dta</code> \u2014 Method.</p> <pre><code>write_dta(df, path)\n</code></pre> <p>Write a DataFrame to a Stata (.dta) file.</p> <p>Arguments</p> <ul> <li><code>df</code>: The DataFrame to be written to a file.</li> <li><code>path</code>: String as path where the .dta file will be created. If a file at this path already exists, it will be overwritten.</li> </ul> <p>Examples</p> <pre><code>julia&gt; df = DataFrame(AA=[\"sav\", \"por\"], AB=[10.1, 10.2]);\n\njulia&gt; write_dta(df, \"test.dta\")\n2\u00d72 ReadStatTable:\n Row \u2502     AA        AB \n     \u2502 String  Float64? \n\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n   1 \u2502    sav      10.1\n   2 \u2502    por      10.2\n</code></pre> <p>source</p> <p># <code>TidierFiles.write_file</code> \u2014 Method.</p> <pre><code>write_files(df, path; args)\n</code></pre> <p>Generic file writer that automatically detects type and dispatches the appropriate read function. </p> <p>Arguments</p> <ul> <li><code>df</code> : Data frame to be exported</li> <li><code>path</code> : a string with the file path to for the location of resulting file</li> <li><code>args</code> : additional arguments supported for that specific file type are given as they normally would be</li> </ul> <p>Examples</p> <pre><code>julia&gt; df = DataFrame(ID = 1:5, Name = [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eva\"], Score = [88, 92, 77, 85, 95]);\n\njulia&gt; write_file(df, \"test.parquet\");\n\njulia&gt; read_file(\"test.parquet\")\n5\u00d73 DataFrame\n Row \u2502 ID     Name     Score \n     \u2502 Int64  String   Int64 \n\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n   1 \u2502     1  Alice       88\n   2 \u2502     2  Bob         92\n   3 \u2502     3  Charlie     77\n   4 \u2502     4  David       85\n   5 \u2502     5  Eva         95\n</code></pre> <p>source</p> <p># <code>TidierFiles.write_parquet</code> \u2014 Method.</p> <pre><code>write_parquet(df, )\n</code></pre> <p>Write a DataFrame to an Parquet (.parquet) file.</p> <p>Arguments</p> <ul> <li><code>df</code>: The DataFrame to be written to a file.</li> <li><code>path</code>: String as path where the .dta file will be created. If a file at this path already exists, it will be overwritten.</li> </ul> <p>Examples</p> <pre><code>julia&gt; df = DataFrame(AA=[\"Par\", \"quet\"], AB=[10.1, 10.2]);\n\njulia&gt; write_parquet(df, \"test.parquet\");\n</code></pre> <p>source</p> <p># <code>TidierFiles.write_sas</code> \u2014 Method.</p> <pre><code>write_sas(df, path)\n</code></pre> <p>Write a DataFrame to a SAS (.sas7bdat or .xpt) file.</p> <p>Arguments</p> <ul> <li><code>df</code>: The DataFrame to be written to a file.</li> <li><code>path</code>: String as path where the .dta file will be created. If a file at this path already exists, it will be overwritten.</li> </ul> <p>Examples</p> <pre><code>julia&gt; df = DataFrame(AA=[\"sav\", \"por\"], AB=[10.1, 10.2]);\n\njulia&gt; write_sas(df, \"test.sas7bdat\")\n2\u00d72 ReadStatTable:\n Row \u2502     AA        AB \n     \u2502 String  Float64? \n\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n   1 \u2502    sav      10.1\n   2 \u2502    por      10.2\n\njulia&gt; write_sas(df, \"test.xpt\")\n2\u00d72 ReadStatTable:\n Row \u2502     AA        AB \n     \u2502 String  Float64? \n\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n   1 \u2502    sav      10.1\n   2 \u2502    por      10.2\n</code></pre> <p>source</p> <p># <code>TidierFiles.write_sav</code> \u2014 Method.</p> <pre><code>write_sav(df, path)\n</code></pre> <p>Write a DataFrame to a SPSS (.sav or .por) file.</p> <p>Arguments</p> <ul> <li><code>df</code>: The DataFrame to be written to a file.</li> <li><code>path</code>: String as path where the .dta file will be created. If a file at this path already exists, it will be overwritten.</li> </ul> <p>Examples</p> <pre><code>julia&gt; df = DataFrame(AA=[\"sav\", \"por\"], AB=[10.1, 10.2]);\n\njulia&gt; write_sav(df, \"test.sav\")\n2\u00d72 ReadStatTable:\n Row \u2502     AA        AB \n     \u2502 String  Float64? \n\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n   1 \u2502    sav      10.1\n   2 \u2502    por      10.2\n\njulia&gt; write_sav(df, \"test.por\")\n2\u00d72 ReadStatTable:\n Row \u2502     AA        AB \n     \u2502 String  Float64? \n\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n   1 \u2502    sav      10.1\n   2 \u2502    por      10.2\n</code></pre> <p>source</p> <p># <code>TidierFiles.write_table</code> \u2014 Method.</p> <pre><code>write_table(x, file; delim = '  ', na, append, col_names, eol, num_threads)\n</code></pre> <p>Write a DataFrame to a file, allowing for customization of the delimiter and other options.</p> <p>Arguments</p> <ul> <li><code>x</code>: The DataFrame to write to a file.</li> <li><code>file</code>: The path to the file where the DataFrame will be written.</li> </ul> <p>-delim: Character to use as the field delimiter. The default is tab ('  '), making it a TSV (tab-separated values) file by default, but can be changed to accommodate other formats.</p> <ul> <li><code>missingstring</code>: The string to represent missing data in the output file.</li> <li><code>append</code>: Whether to append to the file if it already exists. If false, the file will be overwritten.</li> <li><code>col_names</code>: Whether to write column names as the first line of the file. If appending to an existing file with append = true, column names will not be written regardless of this parameter's value.</li> <li><code>eol</code>: The end-of-line character to use in the file. Defaults to \"</li> </ul> <p>\".</p> <ul> <li><code>num_threads</code>: Number of threads to use for writing the file. Uses the number of available Julia threads by default.</li> </ul> <p>Examples</p> <pre><code>julia&gt; df = DataFrame(ID = 1:5, Name = [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eva\"], Score = [88, 92, 77, 85, 95]);\n\njulia&gt; write_table(df, \"tabletest.txt\");\n</code></pre> <p>source</p> <p># <code>TidierFiles.write_tsv</code> \u2014 Method.</p> <pre><code>write_tsv(DataFrame, filepath; na = \"\", append = false, col_names = true, missingstring, eol = \"\n</code></pre> <p>\", num_threads = Threads.nthreads()) Write a DataFrame to a TSV (tab-separated values) file.</p> <p>Arguments</p> <ul> <li><code>x</code>: The DataFrame to write to the TSV file.</li> <li><code>file</code>: The path to the output TSV file.</li> <li><code>missingstring</code>: = \"\": The string to represent missing values in the output file. Default is an empty string.</li> <li><code>append</code>: Whether to append to the file if it already exists. Default is false.</li> <li><code>col_names</code>: = true: Whether to write column names as the first line of the file. Default is true.</li> <li><code>eol</code>: = \"</li> </ul> <p>\": The end-of-line character to use in the output file. Default is the newline character.</p> <ul> <li><code>num_threads</code> = Threads.nthreads(): The number of threads to use for writing the file. Default is the number of available threads.</li> </ul> <p>Examples</p> <pre><code>julia&gt; df = DataFrame(ID = 1:5, Name = [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eva\"], Score = [88, 92, 77, 85, 95]);\n\njulia&gt; write_tsv(df, \"tsvtest.tsv\");\n</code></pre> <p>source</p> <p># <code>TidierFiles.write_xlsx</code> \u2014 Method.</p> <pre><code>write_xlsx(x; path, overwrite)\n</code></pre> <p>Write a DataFrame, or multiple DataFrames, to an Excel file. Specific sheets on can be specified for each dataframe.</p> <p>Arguments</p> <ul> <li><code>x</code>: The data to write. Can be a single Pair{String, DataFrame} for writing one sheet, or a Tuple of such pairs for writing multiple sheets. The String in each pair specifies the sheet name, and the DataFrame is the data to write to that sheet.</li> <li><code>path</code>: The path to the Excel file where the data will be written.</li> <li><code>overwrite</code>: Defaults to false. Whether to overwrite an existing file. If false, an error is thrown when attempting to write to an existing file.</li> </ul> <p>Examples</p> <pre><code>julia&gt; df = DataFrame(integers=[1, 2, 3, 4],\n       strings=[\"This\", \"Package makes\", \"File reading/writing\", \"even smoother\"],\n       floats=[10.2, 20.3, 30.4, 40.5]);\n\njulia&gt; df2 = DataFrame(AA=[\"aa\", \"bb\"], AB=[10.1, 10.2]);\n\njulia&gt; write_xlsx((\"REPORT_A\" =&gt; df, \"REPORT_B\" =&gt; df2); path=\"xlsxtest.xlsx\", overwrite = true);\n</code></pre> <p>source</p> <p></p> <p></p>"},{"location":"reference/#reference-internal-functions","title":"Reference - Internal functions","text":""},{"location":"examples/generated/UserGuide/Arrow/","title":"Arrow Files","text":"<p>Arrow file reading and writing is powered by Arrow.jl</p> <p></p> <p></p>"},{"location":"examples/generated/UserGuide/Arrow/#read_arrow","title":"<code>read_arrow</code>","text":"<p><code>read_arrow(path; skip=0, n_max=Inf, col_select=nothing)</code></p> <p>This function reads an Arrow (.arrow) file into a DataFrame. The arguments are:</p> <ul> <li><code>path</code>: The path to the .arrow file.</li> <li><code>skip</code>: Number of initial rows to skip before reading data. Default is 0.</li> <li><code>n_max</code>: Maximum number of rows to read. Default is <code>Inf</code> (read all rows).</li> <li><code>col_select</code>: Optional vector of symbols or strings to select which columns to load. Default is <code>nothing</code> (load all columns).</li> </ul> <p></p> <p></p>"},{"location":"examples/generated/UserGuide/Arrow/#write_arrow","title":"<code>write_arrow</code>","text":"<p><code>write_arrow(df, path)</code></p> <p>This function writes a DataFrame to an Arrow (.arrow) file. The arguments are:</p> <ul> <li><code>df</code>: The DataFrame to be written to a file.</li> <li><code>path</code>: The path where the .arrow file will be created. If a file at this path already exists, it will be overwritten.</li> <li>Additional arguments for writing arrow files are not outlined here, but should be available through the same interface of <code>Arrow.write</code>. Refer to Arrow.jl documentation at their page for further explanation.</li> </ul> <p>This page was generated using Literate.jl.</p>"},{"location":"examples/generated/UserGuide/delim/","title":"Delimited Files","text":"<p>The goal of reading and writing throughout TidierFiles.jl is to use consistent syntax. This functions on this page focus on delimited files and are powered by CSV.jl.</p> <pre><code>using TidierFiles\n</code></pre> <p></p> <p></p>"},{"location":"examples/generated/UserGuide/delim/#read_csvtsvdelim","title":"read_csv/tsv/delim","text":"<pre><code>read_csv(\"https://raw.githubusercontent.com/TidierOrg/TidierFiles.jl/main/testing_files/csvtest.csv\", skip = 2, n_max = 3, col_select = [\"ID\", \"Score\"], missingstring = [\"4\"])\n\n#read_csv(file; delim=',', col_names=true, skip=0, n_max=Inf, comment=nothing, missingstring=\"\", col_select=nothing, escape_double=true, col_types=nothing, num_threads=1)\n\n#read_tsv(file; delim='\\t', col_names=true, skip=0, n_max=Inf, comment=nothing, missingstring=\"\", col_select=nothing, escape_double=true, col_types=nothing, num_threads=Threads.nthreads())\n\n#read_delim(file; delim='\\t', decimal = '.', groupmark = nothing col_names=true, skip=0, n_max=Inf, comment=nothing, missingstring=\"\", col_select=nothing, escape_double=true, col_types=nothing, num_threads=Threads.nthreads())\n\n#read_csv2(file; delim=';', decimal = ',', col_names=true, skip=0, n_max=Inf, comment=nothing, missingstring=\"\", col_select=nothing, escape_double=true, col_types=nothing, num_threads=Threads.nthreads())\n\n#These functions read a delimited file (CSV, TSV, or custom delimiter) into a DataFrame. The arguments are:\n</code></pre> 3\u00d72 DataFrame RowIDScoreInt64?Int6413772missing853595 <ul> <li><code>file</code>: Path or vector of paths to the file(s) or a URL(s).</li> <li><code>delim</code>: Field delimiter. Default is ',' for <code>read_csv</code>, '\\t' for <code>read_tsv</code> and <code>read_delim</code>.</li> <li><code>col_names</code>: Use first row as column names. Can be <code>true</code>, <code>false</code>, or an array of strings. Default is <code>true</code>.</li> <li><code>skip</code>: Number of lines to skip before reading data. Default is 0.</li> <li><code>n_max</code>: Maximum number of rows to read. Default is <code>Inf</code> (read all rows).</li> <li><code>comment</code>: Character indicating comment lines to ignore. Default is <code>nothing</code>.</li> <li><code>missingstring</code>: String(s) representing missing values. Default is <code>\"\"</code>.</li> <li><code>col_select</code>: Optional vector of symbols or strings to select columns to load. Default is <code>nothing</code>.</li> <li><code>groupmark</code>: A symbol that separates groups of digits Default is <code>nothing</code>.</li> <li><code>decimal</code>: An ASCII Char argument that is used when parsing float values. Default is '.'.</li> <li><code>escape_double</code>: Interpret two consecutive quote characters as a single quote. Default is <code>true</code>.</li> <li><code>col_types</code>: Optional specification of column types. Default is <code>nothing</code> (types are inferred).</li> <li><code>num_threads</code>: Number of threads to use for parallel execution. Default is 1 for <code>read_csv</code> and the number of available threads for <code>read_tsv</code> and <code>read_delim</code>.</li> </ul> <p>The functions return a DataFrame containing the parsed data from the file.</p> <p></p> <p></p>"},{"location":"examples/generated/UserGuide/delim/#write_csv-and-write_tsv","title":"<code>write_csv</code> and <code>write_tsv</code>","text":"<p>writecsv(x, file; missingstring=\"\", append=false, colnames=true, eol=\"\\n\", num_threads=Threads.nthreads())</p> <p>writetsv(x, file; missingstring=\"\", append=false, colnames=true, eol=\"\\n\", num_threads=Threads.nthreads())</p> <p>These functions write a DataFrame to a CSV or TSV file. The arguments are:</p> <ul> <li><code>x</code>: The DataFrame to write.</li> <li><code>file</code>: The path to the output file.</li> <li><code>missingstring</code>: The string to represent missing values. Default is an empty string.</li> <li><code>append</code>: Whether to append to an existing file. Default is <code>false</code>.</li> <li><code>col_names</code>: Whether to write column names as the first line. Default is <code>true</code>.</li> <li><code>eol</code>: The end-of-line character. Default is <code>\"\\n\"</code>.</li> <li><code>num_threads</code>: The number of threads to use for writing. Default is the number of available threads.</li> </ul> <p></p> <p></p>"},{"location":"examples/generated/UserGuide/delim/#read_table","title":"<code>read_table</code>","text":"<p>readtable(file; colnames=true, skip=0, nmax=Inf, comment=nothing, colselect=nothing, missingstring=\"\", num_threads)</p> <p>This function reads a table from a whitespace-delimited file into a DataFrame. The arguments are:</p> <ul> <li><code>file</code>: The path to the file to read.</li> <li><code>col_names</code>: Whether the first non-skipped line contains column names. Default is <code>true</code>.</li> <li><code>skip</code>: Number of lines to skip before processing. Default is 0.</li> <li><code>n_max</code>: Maximum number of lines to read. Default is <code>Inf</code> (read all lines).</li> <li><code>comment</code>: Character or string indicating comment lines to ignore. Default is <code>nothing</code>.</li> <li><code>col_select</code>: Optional vector of symbols or strings to select columns to load. Default is <code>nothing</code>.</li> <li><code>missingstring</code>: The string representing missing values. Default is <code>\"\"</code>.</li> <li><code>num_threads</code>: The number of threads to use for writing. Default is the number of available threads.</li> </ul> <p></p> <p></p>"},{"location":"examples/generated/UserGuide/delim/#write_table","title":"<code>write_table</code>","text":"<p>writetable(x, file; delim='\\t', missingstring=\"\", append=false, colnames=true, eol=\"\\n\", num_threads=Threads.nthreads())</p> <p>This function writes a DataFrame to a file with customizable delimiter and options. The arguments are:</p> <ul> <li><code>x</code>: The DataFrame to write.</li> <li><code>file</code>: The path to the output file.</li> <li><code>delim</code>: The field delimiter. Default is <code>'\\t'</code> (tab-separated).</li> <li><code>missingstring</code>: The string to represent missing values. Default is <code>\"\"</code>.</li> <li><code>append</code>: Whether to append to an existing file. Default is <code>false</code>.</li> <li><code>col_names</code>: Whether to write column names as the first line. Default is <code>true</code>.</li> <li><code>eol</code>: The end-of-line character. Default is <code>\"\\n\"</code>.</li> <li><code>num_threads</code>: The number of threads to use for writing. Default is the number of available threads.</li> </ul> <p>This page was generated using Literate.jl.</p>"},{"location":"examples/generated/UserGuide/parquet/","title":"Parquet Files","text":"<p>Parquet file reading and writing is powered by Parquet2.jl</p> <p></p> <p></p>"},{"location":"examples/generated/UserGuide/parquet/#read_parquet","title":"<code>read_parquet</code>","text":"<p><code>read_parquet(path; col_names=true, skip=0, n_max=Inf, col_select=nothing)</code></p> <p>This function reads a Parquet (.parquet) file into a DataFrame. The arguments are:</p> <ul> <li><code>path</code>: The path or vector of paths or URLs to the .parquet file.</li> <li><code>col_names</code>: Indicates if the first row of the file is used as column names. Default is <code>true</code>.</li> <li><code>skip</code>: Number of initial rows to skip before reading data. Default is 0.</li> <li><code>n_max</code>: Maximum number of rows to read. Default is <code>Inf</code> (read all rows).</li> <li><code>col_select</code>: Optional vector of symbols or strings to select which columns to load. Default is <code>nothing</code> (load all columns).</li> </ul> <p></p> <p></p>"},{"location":"examples/generated/UserGuide/parquet/#write_parquet","title":"<code>write_parquet</code>","text":"<p><code>write_parquet(df, path)</code></p> <p>This function writes a DataFrame to a Parquet (.parquet) file. The arguments are:</p> <ul> <li><code>df</code>: The DataFrame to be written to a file.</li> <li><code>path</code>: The path where the .parquet file will be created. If a file at this path already exists, it will be overwritten.</li> <li>Additional arguments for writing parquet files are not outlined here, but should be available through the same interface of <code>Parquet2.writefile</code>. Refer to documentation at their page for further explanation.</li> </ul> <p>This page was generated using Literate.jl.</p>"},{"location":"examples/generated/UserGuide/stats/","title":"Stats Files","text":"<p>The functions for reading and writing stats files are made possible by ReadStatTables.jl</p> <p></p> <p></p>"},{"location":"examples/generated/UserGuide/stats/#reading-stats-files","title":"reading stats files","text":"<p>readdta(filepath; encoding=nothing, colselect=nothing, skip=0, nmax=Inf, numthreads=1) readsas(filepath; encoding=nothing, colselect=nothing, skip=0, nmax=Inf, numthreads=1) readsav(filepath; encoding=nothing, colselect=nothing, skip=0, nmax=Inf, numthreads=1)</p> <p>These functions read data from Stata (.dta), SAS (.sas7bdat and .xpt), and SPSS (.sav and .por) files into a DataFrame. The arguments are:</p> <ul> <li><code>filepath</code>: The path to the file or a URL pointing to the file. If a URL is provided, the file will be downloaded and then read.</li> <li><code>encoding</code>: Optional; specifies the encoding of the input file. Default is the package's or function's default.</li> <li><code>col_select</code>: Optional; allows specifying a subset of columns to read. Can be a vector of column names or indices. Default is <code>nothing</code> (all columns are read).</li> <li><code>skip</code>: Number of rows to skip at the beginning of the file. Default is 0.</li> <li><code>n_max</code>: Maximum number of rows to read after skipping. Default is <code>Inf</code> (read all rows).</li> <li><code>num_threads</code>: Number of concurrent tasks or threads to use for processing. Default is 1.</li> </ul> <p></p> <p></p>"},{"location":"examples/generated/UserGuide/stats/#writing-stats-files","title":"writing stats files","text":"<p>writesav(df, path) writesas(df, path) write_dta(df, path)</p> <p>These functions write a DataFrame to SPSS (.sav or .por), SAS (.sas7bdat or .xpt), and Stata (.dta) files. The arguments are:</p> <ul> <li><code>df</code>: The DataFrame to be written to a file.</li> <li><code>path</code>: The path where the file will be created. If a file at this path already exists, it will be overwritten.</li> </ul> <p>This page was generated using Literate.jl.</p>"},{"location":"examples/generated/UserGuide/xl/","title":"Excel Files","text":"<p>Reading and writing XLSX files are made possible by XLSX.jl</p> <p></p> <p></p>"},{"location":"examples/generated/UserGuide/xl/#read_xlsx","title":"<code>read_xlsx</code>","text":"<p>readxlsx(path; sheet=nothing, range=nothing, colnames=true, coltypes=nothing, missingstring=\"\", trimws=true, skip=0, nmax=Inf, guessmax=nothing)</p> <p>This function reads data from an Excel file into a DataFrame. The arguments are:</p> <ul> <li><code>path</code>: The path or URL to the Excel file to be read.</li> <li><code>sheet</code>: The sheet to be read. Can be a sheet name (string) or index (integer). Default is the first sheet.</li> <li><code>range</code>: A specific range of cells to be read from the sheet. Default is the entire sheet.</li> <li><code>col_names</code>: Whether the first row of the range contains column names. Default is <code>true</code>.</li> <li><code>col_types</code>: Explicit specification of column types. Can be a single type, a list, or a dictionary mapping column names or indices to types. Default is <code>nothing</code> (types are inferred).</li> <li><code>missingstring</code>: The string representing missing values. Default is <code>\"\"</code>.</li> <li><code>trim_ws</code>: Whether to trim leading and trailing whitespace from cells. Default is <code>true</code>.</li> <li><code>skip</code>: Number of rows to skip before reading data. Default is 0.</li> <li><code>n_max</code>: Maximum number of rows to read. Default is <code>Inf</code> (read all rows).</li> <li><code>guess_max</code>: Maximum number of rows to scan for type guessing and column names detection. Default is <code>nothing</code> (a default heuristic is used).</li> </ul> <p></p> <p></p>"},{"location":"examples/generated/UserGuide/xl/#write_xlsx","title":"<code>write_xlsx</code>","text":"<p>write_xlsx(x; path, overwrite=false)</p> <p>This function writes a DataFrame, or multiple DataFrames, to an Excel file. The arguments are:</p> <ul> <li><code>x</code>: The data to write. Can be a single <code>Pair{String, DataFrame}</code> for writing one sheet, or a <code>Tuple</code> of such pairs for writing multiple sheets. The <code>String</code> in each pair specifies the sheet name, and the <code>DataFrame</code> is the data to write to that sheet.</li> <li><code>path</code>: The path to the output Excel file.</li> <li><code>overwrite</code>: Whether to overwrite an existing file. Default is <code>false</code>.</li> </ul> <p></p> <p></p>"},{"location":"examples/generated/UserGuide/xl/#writing-to-a-specific-sheet","title":"Writing to a specific sheet","text":"<p>The example below demonstrates how to write to specific sheets in a file. THe string in the Dict is the sheet name, it can be new or preexisting. The second component is the dataframe to be written to that sheet.</p> <pre><code>write_xlsx((\"REPORT_A\" =&gt; df, \"REPORT_C\" =&gt; df2); path = \"/Users/danielrizk/Downloads/xlsxtest2.xlsx\", overwrite = true)\n</code></pre> <p>This page was generated using Literate.jl.</p>"}]}